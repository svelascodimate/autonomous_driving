Systematic Evaluation of Bugs in Software Defined Vehicles
================

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## Table of Contents

- [Introduction](#introduction)
- [Features](#features)
- [Installation](#installation)

## Introduction

Welcome to our repository, serving as the foundational codebase for our
class project on repository mining and topic modeling for bugs in
Software Defined Vehicles. This repository is meticulously organized to
facilitate easy access and understanding of our methodologies and
datasets. Here’s a brief overview of what you’ll find inside:

- `core/01_github_miner.ipynb`: Methods for mining issues from software
  repositories

- `core/01_topic_modeling.ipynb`: Methods for topic modeling using
  SentenceBERT

- `nbs/miner_nb.ipynb`: This is notebook designed to streamline the
  mining process. It’s set up for immediate use, allowing you to execute
  the mining procedures with ease and precision.

- `nbs/modeling_nb.ipynb`: This notebook is dedicated to executing the
  topic modeling process.

Visualizations are hosted in colab:
(notebook)\[https://colab.research.google.com/drive/1NUnCK-vBq_YaB8O_d5Y-iBv4tLkkhySw?usp=sharing\]

- `/data/`: This directory contains the mined issues that we used in our
  project, this a valuable resource for anyone looking to explore
  real-world data or validate their own mining and modeling techniques.

## Features

- **Robust GitHub Mining**: Leveraging the power of the [GitHub REST
  API](https://docs.github.com/en/rest/issues?apiVersion=2022-11-28),
  our tool adeptly mines issues from GitHub repositories. It allows
  users to define specific search criteria, ensuring targeted and
  efficient data extraction tailored to your research needs.

- **Advanced Topic Modeling**: At the core of our approach is the use of
  the [Transformers library](https://pypi.org/project/transformers/)
  from Hugging Face, renowned for its extensive range of pre-trained
  BERT models. For our topic modeling, we employ the [all-mpnet-base-v2
  model](https://huggingface.co/sentence-transformers/all-mpnet-base-v2),
  a powerful encoder-based transformer known for its accuracy and
  efficiency in handling complex language data.

- **Enhanced Clustering Descriptions with GPT-4**: To add depth and
  clarity to our analysis, we integrate OpenAI’s GPT-4, a cutting-edge
  decoder-based transformer. This AI model significantly enhances the
  descriptions of extracted keywords for each topic, providing richer,
  more insightful interpretations of the data clusters.

## Installation

First, create a virtual environment using nvdeb or conda:

### Using venv

1.  **Create a Virtual Environment**:  
    Run the following command to create a virtual environment named
    `myenv`. This command creates a directory `myenv` in your current
    directory, which will contain the Python interpreter and libraries
    for this environment.

    ``` bash
    python -m venv myenv
    ```

2.  **Activate the Virtual Environment**:

    - On Windows, activate the environment with:

      ``` bash
      myenv\Scripts\activate
      ```

    - On macOS and Linux, use:

      ``` bash
      source myenv/bin/activate
      ```

Once activated, your command line will show the name of the virtual
environment, indicating that it is active. In this state, any Python
packages you install will be contained within this environment, separate
from the global Python installation.

Next, you need to setup nbdev, to compile our library and also install
the required dependencies:

``` bash
   pip install nbdev
```

Once installed, execute the following commands:

First install project dependencies

``` bash
pip install .
```

Next, compile and install our library:

``` bash
nbdev_export
```

``` bash
pip install .
```
